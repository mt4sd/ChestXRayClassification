{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486aa738",
   "metadata": {},
   "source": [
    "# Split PadChest dataset into different subsets to train the models for each pathology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5233ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74abc8f",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7310e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../CodeChestXRay/TrainXray/Data/PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3cbfb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images PA in PadChest512 (excluding the labels “exclude” o “suboptimal study”and manually filtered): 87946\n"
     ]
    }
   ],
   "source": [
    "# Read labels from CSV file \n",
    "csv_table = pd.read_csv('C:/Users/maria/OneDrive/Documentos/Escritorio/CodeChestXRay/TrainXray/Data/PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv', low_memory = False)\n",
    "\n",
    "# Replace missing values in \"Labels\" column with an empty string\n",
    "csv_table['Labels'].fillna('', inplace = True)\n",
    "\n",
    "# Remove Labels that contains the Labels 'exclude' or 'suboptimal study'\n",
    "csv_table = csv_table[~csv_table[\"Labels\"].str.contains('exclude')]\n",
    "csv_table = csv_table[~csv_table[\"Labels\"].str.contains('suboptimal study')]\n",
    "\n",
    "# Projection PA\n",
    "csv_table = csv_table[csv_table['Projection'] == 'PA']\n",
    "\n",
    "# Filter the imeges by the available IDs\n",
    "avail_imgID = os.path.join(\"PadChest_512_PA_manually_filtered_87946.txt\")\n",
    "\n",
    "with open(avail_imgID, \"r\") as f:\n",
    "    avail_imgID = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "csv_table = csv_table[csv_table[\"ImageID\"].isin(avail_imgID)]\n",
    "\n",
    "print(\"Images PA in PadChest512 (excluding the labels “exclude” o “suboptimal study”\"+\n",
    "      f\"and manually filtered): {len(csv_table)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c96162",
   "metadata": {},
   "source": [
    "## Obtain the occurrence of each pathology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acdf91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = {\n",
    "    \n",
    "    \"Infiltrations\": [\"infiltrates\", \"interstitial pattern\", \"ground glass pattern\",\n",
    "                      \"reticular interstitial pattern\", \"reticulonodular interstitial pattern\",\n",
    "                      \"alveolar pattern\", \"consolidation\", \"air bronchogram\"],\n",
    "    \n",
    "    \"Atelectasis\": [\"atelectasis\"],\n",
    "    \n",
    "    \"Nodule\": [\"nodule\", \"multiple nodules\"],\n",
    "    \n",
    "    \"Mass\": [\"pulmonary mass\"],\n",
    "    \n",
    "    \"Cavitation\": [\"cavitation\", \"abscess\", \"cyst\"],\n",
    "    \n",
    "    \"Air Trapping\": [\"air trapping\"],\n",
    "    \n",
    "    \"Cardiomegaly\": [\"cardiomegaly\"],\n",
    "    \n",
    "    \"Heart Insufficiency\": [\"heart insufficiency\"],\n",
    "    \n",
    "    \"Pleural Effusion\": [\"pleural effusion\"],\n",
    "    \n",
    "    \"Pneumothorax\": [\"pneumothorax\"],\n",
    "    \n",
    "    \"Rib Fracture\": [\"rib fracture\"],\n",
    "    \n",
    "    \"Thoracic Cage Deformation\": [\"thoracic cage deformation\"],\n",
    "    \n",
    "    \"Mediastinal Conditions\": [\"mediastinal shift\", \"mediastinal mass\", \"pneumomediastinum\"],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de5dee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infiltrations: 7503\n",
      "Atelectasis: 3839\n",
      "Nodule: 3540\n",
      "Mass: 520\n",
      "Cavitation: 284\n",
      "Air Trapping: 3239\n",
      "Cardiomegaly: 8114\n",
      "Heart Insufficiency: 679\n",
      "Pleural Effusion: 3205\n",
      "Pneumothorax: 217\n",
      "Rib Fracture: 2080\n",
      "Thoracic Cage Deformation: 151\n",
      "Mediastinal Conditions: 225\n"
     ]
    }
   ],
   "source": [
    "for pathology, labels in conditions.items():\n",
    "    category = ', '.join(labels)\n",
    "    csv_table_filtered = csv_table[csv_table['Labels'].str.contains('|'.join(labels))]\n",
    "    count = len(csv_table_filtered)\n",
    "    print(f\"{pathology}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a2d247",
   "metadata": {},
   "source": [
    "### Create subsets containing the pathology and not containing the pathology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b88272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets_with_pathology = {}  # Dictionary to store subsets with pathology\n",
    "subsets_without_pathology = {}  # Dictionary to store subsets without pathology\n",
    "\n",
    "# Iterate over the conditions dictionary\n",
    "for pathology, labels in conditions.items():\n",
    "    category = ', '.join(labels)\n",
    "    subset_with_pathology = csv_table[csv_table['Labels'].str.contains('|'.join(labels))]\n",
    "\n",
    "    # Randomly sample the subset without pathology to match the number of samples in the subset with pathology\n",
    "    subset_without_pathology = csv_table[~csv_table['Labels'].str.contains('|'.join(labels))].sample(len(subset_with_pathology), replace=True)\n",
    "\n",
    "    subsets_with_pathology[pathology] = subset_with_pathology\n",
    "    subsets_without_pathology[pathology] = subset_without_pathology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee53dcae",
   "metadata": {},
   "source": [
    "### Create a list to store the image IDs for each subsets combining positive/negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfa5090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_label_list(df, sample_size = None):\n",
    "    image_label_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        image_label_list.append((row['ImageID'], row['Labels']))\n",
    "    \n",
    "    if sample_size is not None:\n",
    "        image_label_list = random.sample(image_label_list, sample_size)\n",
    "    \n",
    "    return image_label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501dc40",
   "metadata": {},
   "source": [
    "### Divide each subset into training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4757cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pathology, labels in conditions.items():\n",
    "    \n",
    "    # Get the subset with pathology and create the corresponding image_label_list\n",
    "    subset_with_pathology = subsets_with_pathology[pathology]\n",
    "    yes_list = get_image_label_list(subset_with_pathology)\n",
    "    \n",
    "    # Get the subset without pathology and create the corresponding image_label_list\n",
    "    subset_without_pathology = subsets_without_pathology[pathology]\n",
    "    not_list = get_image_label_list(subset_without_pathology)\n",
    "    \n",
    "    # Combine the lists\n",
    "    combined_list = not_list + yes_list\n",
    "    \n",
    "    # Combine the lists\n",
    "    train_imgs = []\n",
    "    valid_imgs = []\n",
    "    test_imgs = []\n",
    "\n",
    "    # Loop through the dictionary and split each list into train, validation, and test sets\n",
    "\n",
    "    train, test = train_test_split(combined_list, test_size=0.10, random_state=42)\n",
    "    train, valid = train_test_split(train, test_size=0.1, random_state=42)\n",
    "    \n",
    "    #Write the image IDs in a txt file\n",
    "    with open(f\"{pathology}_train_imageIDs.txt\", \"w\") as file:\n",
    "        for imageID in train:\n",
    "            file.write(str(imageID[0]) + \"\\n\")\n",
    "\n",
    "        with open(f\"{pathology}_valid_imageIDs.txt\", \"w\") as file:\n",
    "            for imageID in valid:\n",
    "                file.write(str(imageID[0]) + \"\\n\")\n",
    "\n",
    "        with open(f\"{pathology}_test_imageIDs.txt\", \"w\") as file:\n",
    "            for imageID in test:\n",
    "                file.write(str(imageID[0]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6fb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
