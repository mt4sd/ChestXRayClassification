{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d2f59f9",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5233ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe5002",
   "metadata": {},
   "source": [
    "## Save all the images in the same folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1243f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 157105\n"
     ]
    }
   ],
   "source": [
    "# Main folder that contains the images\n",
    "root_folder = 'BIMCV-PadChest-FULL-resized512'\n",
    "\n",
    "# List to store the paths of the images\n",
    "images = []\n",
    "\n",
    "# We walk the structure of folders and subfolders with os.walk()\n",
    "for root, dirs, files in os.walk(root_folder):\n",
    "    for file in files:\n",
    "        # We check if the file is an image\n",
    "        if file.endswith(\".png\"):\n",
    "            # If it is an image, we add the path to the list\n",
    "            image_path = os.path.join(root, file)\n",
    "            images.append(image_path)\n",
    "            \n",
    "# Print the length of the list of image paths\n",
    "print(\"Number of images:\", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d03a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the destination folder if it does not already exist\n",
    "dest_path = 'PadChest512_Full'\n",
    "if not os.path.exists(dest_path):\n",
    "    os.makedirs(dest_path)\n",
    "\n",
    "# Copy each image to the destination folder\n",
    "for image in images:\n",
    "    shutil.copy(image, dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f4d8a2",
   "metadata": {},
   "source": [
    "## Load the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d408bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths of the folders containing the images and the CSV file\n",
    "dest_path = 'PadChest512_Full'\n",
    "csv_path = 'CodeChestXRay/TrainXray/Data/PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ead7e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "csv_table = pd.read_csv(csv_path, low_memory = False)\n",
    "\n",
    "#---------------------Filters--------------------: \n",
    "imageIDs_available = \"CodeChestXRay/TrainXray/normal_classification/normal_classify_training/Resources/available_imageIDs_PadChest512.txt\"\n",
    "with open(imageIDs_available, \"r\") as f:\n",
    "    avail_imgID = [line.strip() for line in f.readlines()]   \n",
    "\n",
    "# Filter by available image ID\n",
    "if avail_imgID:\n",
    "    csv_table= csv_table[csv_table[\"ImageID\"].isin(avail_imgID)]\n",
    "        \n",
    "# Filter by projection\n",
    "csv_table = csv_table[csv_table[\"Projection\"].isin([\"PA\"])]\n",
    "\n",
    "# Remove Labels that contains the Labels 'exclude' or 'suboptimal study'\n",
    "csv_table[\"Labels\"] = csv_table[\"Labels\"].astype(str)\n",
    "csv_table = csv_table[~csv_table[\"Labels\"].str.contains('exclude')]\n",
    "csv_table = csv_table[~csv_table[\"Labels\"].str.contains('suboptimal study')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b8d4346d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PA and not exclude or suboptimal study: 88018\n"
     ]
    }
   ],
   "source": [
    "print(\"PA and not exclude or suboptimal study:\",len(csv_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af96ccd",
   "metadata": {},
   "source": [
    "## Save the PA images in a new  folder: PadChest512_PA_Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a81504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageIDs = csv_table['ImageID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9180317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in imageIDs:\n",
    "    source_path = os.path.join(dest_path, img)\n",
    "    target_path = os.path.join('PadChest512_PA_Full', img)\n",
    "    shutil.copy(source_path, target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0997daf3",
   "metadata": {},
   "source": [
    "## We delete some samples manually: PadChest522_PA_Manually_Filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9025de2b",
   "metadata": {},
   "source": [
    "### Discard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "96f367ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PA images available 88018\n"
     ]
    }
   ],
   "source": [
    "tatal_PA_IDs = [name for name in os.listdir('PadChest512_PA_Full')]\n",
    "print('PA images available %s' % (len(tatal_PA_IDs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "be4a1a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PA images available after filtering: 87946\n"
     ]
    }
   ],
   "source": [
    "image_validIDs = [name for name in os.listdir('PadChest512_PA_Manually_filtered')]\n",
    "print('PA images available after filtering: %s' % (len(image_validIDs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1b4794e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the image IDs that have been removed manually\n",
    "remove = list(set(tatal_PA_IDs) - set(image_validIDs))\n",
    "\n",
    "# Write the discard image IDs in a txt file\n",
    "with open(\"discard_manually_PA_imageIDs.txt\", \"w\") as f:\n",
    "    for imageID in remove:\n",
    "        f.write(imageID + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4d4ad323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images deleted: 72\n"
     ]
    }
   ],
   "source": [
    "with open('discard_manually_PA_imageIDs.txt', \"r\") as f:\n",
    "    deleted_imageID = [line.strip() for line in f.readlines()]  \n",
    "    print('Images deleted: %s' % (len(deleted_imageID)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8129e27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the available images in a txt\n",
    "with open('available_imageIDs_PC512_PA_filtered.txt', 'w') as f:\n",
    "    for filename in os.listdir('PadChest512_PA_Manually_filtered'):\n",
    "        if filename.endswith('.png'):\n",
    "            f.write(filename + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74abc8f",
   "metadata": {},
   "source": [
    "## Create a txt file with the train, valid and test images (balance normal and abnormal images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d3cbfb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "csv_table = pd.read_csv(csv_path, low_memory = False)\n",
    "\n",
    "#---------------------Filters--------------------: \n",
    "imageIDs_available = \"available_imageIDs_PC512_PA_filtered.txt\"\n",
    "with open(imageIDs_available, \"r\") as f:\n",
    "    avail_imgID = [line.strip() for line in f.readlines()] \n",
    "    \n",
    "# Filter by available image ID\n",
    "if avail_imgID:\n",
    "    csv_table= csv_table[csv_table[\"ImageID\"].isin(avail_imgID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0eabc2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87946"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csv_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "357f1f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all images with their respective labels\n",
    "images_list = []\n",
    "for index, row in csv_table.iterrows():\n",
    "    images_list.append((row['ImageID'], row['Labels']))\n",
    "\n",
    "# Calculate the number of normal and pathological images\n",
    "normal_images = [img for img in images_list if img[1] == \"['normal']\"]\n",
    "pathological_images = [img for img in images_list if img[1] != \"['normal']\"]\n",
    "\n",
    "# Count the number of images in each category\n",
    "num_normal_images = len(normal_images)\n",
    "num_pathological_images = len(pathological_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e7f709c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal images: 33366\n",
      "Abnormal images: 54580\n",
      "Total number of images: 87946\n"
     ]
    }
   ],
   "source": [
    "print('Normal images:',num_normal_images)\n",
    "print('Abnormal images:',num_pathological_images)\n",
    "print('Total number of images:',len(images_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d4f44d",
   "metadata": {},
   "source": [
    "### Sample pathological images and write the samples in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5426b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathologica_images_sampled = random.sample(pathological_images, 35000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3c1bc881",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sampled_phatological_35000.txt\", \"w\") as file:\n",
    "    for imageID in pathologica_images_sampled:\n",
    "        file.write(str(imageID[0]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ed156f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal images: 33366\n",
      "Abnormal images: 35000\n",
      "Total number of images: 68366\n"
     ]
    }
   ],
   "source": [
    "print('Normal images:',num_normal_images)\n",
    "print('Abnormal images:',len(pathologica_images_sampled))\n",
    "print('Total number of images:',num_normal_images + len(pathologica_images_sampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43916df5",
   "metadata": {},
   "source": [
    "### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c0835d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"normal\" and \"pathological\" image lists into two parts with a ratio of 90% and 10%\n",
    "train_normal, valid_normal = train_test_split(normal_images, test_size = 0.1, random_state = 42)\n",
    "train_pathological, valid_pathological = train_test_split(pathologica_images_sampled, test_size=0.1, random_state = 42)\n",
    "\n",
    "# Concatenate the two lists of \"normal\" and \"pathological\" images\n",
    "train_imgs = train_normal + train_pathological\n",
    "valid_imgs = valid_normal + valid_pathological\n",
    "\n",
    "# Split the list of images into two parts with a ratio of 90% and 10%\n",
    "train_imgs, test_imgs = train_test_split(train_imgs, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d1771",
   "metadata": {},
   "source": [
    "### Write the image IDs in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d3203c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Full_PA_balanced_test_imageIDs.txt\", \"w\") as file:\n",
    "    for imageID in test_imgs:\n",
    "        file.write(str(imageID[0]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6bd32",
   "metadata": {},
   "source": [
    "### Count the number of images in each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8ae11d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize counters\n",
    "normal_train = 0\n",
    "normal_valid = 0\n",
    "normal_test = 0\n",
    "pathological_train = 0\n",
    "pathological_valid = 0\n",
    "pathological_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a5256041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of normal images in train dataset: 27001\n",
      "Number of pathological images in train dataset: 28375\n",
      "--------------------------------------------------------------\n",
      "Number of normal images in valid dataset: 3337\n",
      "Number of pathological images in valid dataset: 3500\n",
      "--------------------------------------------------------------\n",
      "Number of normal images in test dataset: 3028\n",
      "Number of pathological images in test dataset: 3125\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the images in each folder and count them based on their label\n",
    "i = 0\n",
    "for img_name in train_imgs:\n",
    "    img_name = train_imgs[i][0]\n",
    "    # Check if image name exists in the CSV file\n",
    "    if img_name in csv_table['ImageID'].values:\n",
    "        # Get the corresponding row in the CSV file\n",
    "        row = csv_table[csv_table['ImageID'] == img_name]\n",
    "        # Check if the image is labeled as normal\n",
    "        if \"['normal']\" in row['Labels'].values:\n",
    "            normal_train += 1\n",
    "        else:\n",
    "            pathological_train += 1\n",
    "        i+=1\n",
    "            \n",
    "# Print the number of normal images in the directory\n",
    "print(\"Number of normal images in train dataset:\", normal_train)\n",
    "print(\"Number of pathological images in train dataset:\", pathological_train)\n",
    "\n",
    "print(\"--------------------------------------------------------------\")\n",
    "\n",
    "i=0\n",
    "for img_name in valid_imgs:\n",
    "    img_name = valid_imgs[i][0]\n",
    "    # Check if image name exists in the CSV file\n",
    "    if img_name in csv_table['ImageID'].values:\n",
    "        # Get the corresponding row in the CSV file\n",
    "        row = csv_table[csv_table['ImageID'] == img_name]\n",
    "        # Check if the image is labeled as normal\n",
    "        if \"['normal']\" in row['Labels'].values:\n",
    "            normal_valid += 1\n",
    "        else:\n",
    "            pathological_valid += 1\n",
    "        i+=1\n",
    "\n",
    "# Print the number of normal images in the directory\n",
    "print(\"Number of normal images in valid dataset:\", normal_valid)\n",
    "print(\"Number of pathological images in valid dataset:\", pathological_valid)\n",
    "\n",
    "print(\"--------------------------------------------------------------\")\n",
    "\n",
    "i=0\n",
    "for img_name in test_imgs:\n",
    "    img_name = test_imgs[i][0]\n",
    "    # Check if image name exists in the CSV file\n",
    "    if img_name in csv_table['ImageID'].values:\n",
    "        # Get the corresponding row in the CSV file\n",
    "        row = csv_table[csv_table['ImageID'] == img_name]\n",
    "        # Check if the image is labeled as normal\n",
    "        if \"['normal']\" in row['Labels'].values:\n",
    "            normal_test += 1\n",
    "        else:\n",
    "            pathological_test += 1\n",
    "    i+=1\n",
    "\n",
    "# Print the number of normal images in the directory\n",
    "print(\"Number of normal images in test dataset:\", normal_test)\n",
    "print(\"Number of pathological images in test dataset:\", pathological_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94d6cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
